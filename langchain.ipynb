{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secret_keys import openai_api_key, azure_openai_api_key, azure_openai_endpoint, azure_openai_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = azure_openai_api_key\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = azure_openai_endpoint\n",
    "os.environ['OPENAI_API_VERSION'] = azure_openai_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Model:  Here are three fancy name suggestions for your Italian restaurant:\n",
      "\n",
      "1. **Trattoria Bella Notte**  \n",
      "   (Translation: \"Beautiful Night\") - Evokes a romantic and inviting atmosphere.\n",
      "\n",
      "2. **Ristorante La Dolce Vita**  \n",
      "   (Translation: \"The Sweet Life\") - Captures the essence of enjoying life through exquisite food.\n",
      "\n",
      "3. **Osteria di Sogni**  \n",
      "   (Translation: \"Tavern of Dreams\") - Suggests a place where culinary dreams come to life.\n",
      "\n",
      "Let me know if you need more options!\n"
     ]
    }
   ],
   "source": [
    "#llm = AzureOpenAI(temperature=0.6, deployment_name='gpt-35-turbo')\n",
    "#name = llm(\"I want to open a restaurent for Indian food. Suggest three fancy name for this\")\n",
    "#print(\"LLM:\", name)\n",
    "\n",
    "llm_chat = AzureChatOpenAI(temperature=0.6, deployment_name='gpt-4o-mini')\n",
    "name = llm_chat.predict(\"I want to open a restaurent for Italian food. Suggest three fancy name for this\")\n",
    "print(\"Chat Model: \", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cusine'],\n",
    "    template = \"I want to open a restaurent for {cusine} food. Suggest a fancy name for it. Only one name please.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cusine=\"Mexican\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Suggent some menu items for {restaurant_name}, Return it as comma separated list \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "name_chain = LLMChain(llm = llm_chat, prompt=prompt_template_name)\n",
    "food_items_chain = LLMChain(llm=llm_chat, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tacos al Pastor, Enchiladas Verdes, Chiles Rellenos, Mole Poblano, Guacamole with Chips, Ceviche de Camar√≥n, Arroz con Pollo, Quesadillas de Huitlacoche, Tamales de Elote, Flan de Coco, Tres Leches Cake, Horchata, Agua Fresca de Jamaica, Sopes de Carnitas, Pozole Rojo.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
    "response = chain.run(\"Mexican\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = LLMChain(llm = llm_chat, prompt=prompt_template_name, output_key='restaurant_name')\n",
    "food_items_chain = LLMChain(llm=llm_chat, prompt=prompt_template_items, output_key='menu_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130441/3879089836.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  seq_chain(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cusine': 'Arabic',\n",
       " 'restaurant_name': '\"Arabesque Delights\"',\n",
       " 'menu_items': 'Sure! Here are some menu items for \"Arabesque Delights\": \\n\\nHummus with Pita, Falafel Wrap, Shawarma Plate, Stuffed Grape Leaves, Tabouleh Salad, Lamb Kofta Skewers, Chicken Mandi, Grilled Eggplant with Tahini, Spiced Rice Pilaf, Baklava with Honey Syrup, Mint Tea, Fattoush Salad, Moroccan Tagine, Zaatar Manakish, Date and Walnut Delight.'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "seq_chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cusine'],\n",
    "    output_variables = ['restaurant_name', 'menu_items']\n",
    ")\n",
    "\n",
    "seq_chain(\n",
    "    {'cusine' : 'Arabic'}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
